{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Shape Runthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a basis for all imported objects\n",
    "PATH = \"../input/four-shapes/shapes/\"\n",
    "IMG_SIZE = 64 # Since 64x64 imgs\n",
    "Shapes = [\"circle\", \"square\", \"triangle\", \"star\"]\n",
    "\n",
    "# Create holding arrays for images\n",
    "Labels = []\n",
    "Dataset = []\n",
    "\n",
    "# Parse through each folder and pull all images\n",
    "for shape in Shapes:\n",
    "    print(\"Getting data for\", shape)\n",
    "    #iterate through each file in the folder\n",
    "    for path in os.listdir(PATH + shape):\n",
    "        #add the image to the list of images\n",
    "        img = cv2.imread(PATH + shape + '/' + path)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        Dataset.append(img)\n",
    "        #add an integer to the labels list \n",
    "        Labels.append(Shapes.index(shape))\n",
    "        \n",
    "# Print results\n",
    "print(\"\\nDataset Images size:\", len(Dataset))\n",
    "print(\"Image Shape:\", Dataset[0].shape)\n",
    "print(\"Labels size:\", len(Labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images\n",
    "Dataset = np.array(Dataset)\n",
    "Dataset = Dataset.astype(\"float32\") / 255.0\n",
    "\n",
    "# One hot encode labels (preventing any integer relation from forming)\n",
    "Labels = np.array(Labels)\n",
    "Labels = to_categorical(Labels)\n",
    "\n",
    "# Split Dataset to train\\test\n",
    "(trainX, testX, trainY, testY) = train_test_split(Dataset, Labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X Train shape:\", trainX.shape)\n",
    "print(\"X Test shape:\", testX.shape)\n",
    "print(\"Y Train shape:\", trainY.shape)\n",
    "print(\"Y Test shape:\", testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture (Deep Learning Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layer to accept images\n",
    "input_layer = Input((64,64,3))\n",
    "\n",
    "# Flatten the input for dense processing\n",
    "x = Flatten()(input_layer)\n",
    "\n",
    "# Compute some dense layer processing\n",
    "x = Dense(300, activation = 'relu')(x)\n",
    "x = Dense(200, activation = 'relu')(x)\n",
    "x = Dense(150, activation = 'relu')(x)\n",
    "\n",
    "# Output layer as an integer value\n",
    "output_layer = Dense(len(Shapes), activation = 'softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the optimizer\n",
    "opt = Adam(lr=0.0005)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(trainX\n",
    "          , trainY\n",
    "          , batch_size=32\n",
    "          , epochs=10\n",
    "          , shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try to test this against the test data\n",
    "model.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See visually the predictions made\n",
    "CLASSES = np.array(Shapes)\n",
    "\n",
    "preds = model.predict(testX)\n",
    "preds_single = CLASSES[np.argmax(preds, axis = -1)]\n",
    "actual_single = CLASSES[np.argmax(testY, axis = -1)]\n",
    "\n",
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(testX)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    img = testX[idx]\n",
    "    ax = fig.add_subplot(1, n_to_show, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, 'pred = ' + str(preds_single[idx]), fontsize=10, ha='center', transform=ax.transAxes) \n",
    "    ax.text(0.5, -0.7, 'act = ' + str(actual_single[idx]), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This testing has shown that even with just a simple deep learning network, shapes can be easily identified by this system, and since the shapes are black images on a white background, with high contrast and little noise, a convolutional neural network would not be necessary to improve the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
