{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows',None)\npd.set_option('display.max_columns',None)\npd.set_option('display.width',None)\npd.set_option('display.max_colwidth',None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Essentials"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing = pd.read_csv(r\"../input/house-prices-advanced-regression-techniques/train.csv\")\nhousing.drop(['Id'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Dealing with missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Fixing missing values explicitly\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing categorical columns with None\n'''\ncat_columns = ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n       'SaleType', 'SaleCondition']\n'''\ndf = housing\ncat_columns = df.select_dtypes(include=['object']).columns\n\nfor col in cat_columns:\n    df[col] = df[col].fillna(\"None\")\n\n#Changing LotFrontage to mean LotFrontage in the same Neighborhood\ndf['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n\n#Replacing numerical column null values with 0\nnum_columns = df.select_dtypes(exclude=['object']).columns\nfor col in num_columns:\n    if col is not 'Electrical':\n        df[col] = df[col].fillna(int(0))\n\n#Replacing 'Electrical' with mode\ndf['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])\n\n#Dropping Utilities\ndf = df.drop(['Utilities'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the count of null values again\ndf.isnull().apply(sum).max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Dealing with Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing noisy data which is above 0.999 quantile\nnum_attributes = df[num_columns]\n\nhigh_quant = df.quantile(.999)\n\nfor col in num_columns:\n    df = df.drop(df[col][df[col]>high_quant[col]].index)\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Dealing with correlated attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing highly correlated features calculated in the EDA Notebook while viewing scatter plot and corr values\n\nattributes_drop = ['MiscVal', 'MoSold', 'YrSold', 'BsmtFinSF2', 'BsmtHalfBath', 'MSSubClass', 'GarageArea',\n                  'GarageYrBlt', '3SsnPorch']\ndf.drop(attributes_drop, axis=1, inplace=True)\n\n# Removing columns with lots of missing values - PoolQC: 1453, MiscFeature: 1406, Alley: 1369, Fence: 1179\nattributes_drop = ['PoolQC', 'MiscFeature', 'Alley', 'Fence']\ndf.drop(attributes_drop, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Handling Text and Categorical Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.select_dtypes(include=['object']).columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Handling Text and Categorical Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transforming Categorial variables using OneHotEncoder\ncat_encoder = OneHotEncoder()\ndf_cat_processed = cat_encoder.fit_transform(df)\ndf_cat_processed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separate features and target variables\nhousing_X = df.drop('SalePrice', axis=1)\nhousing_y = df['SalePrice']\n\n# Getting list of numerical and categorical values separately\nnum_attributes = housing_X.select_dtypes(exclude=['object'])\ncat_attributes = housing_X.select_dtypes(include=['object'])\n\nnum_attribs = list(num_attributes)\ncat_attribs = list(cat_attributes)\n\n# Numerical pipeline to impute any missing values with the median and scale attributes\nnum_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy=\"median\")),\n    ('std_scaler', StandardScaler())\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Full pipeline that handles both numerical and categorical column's transformation\nfull_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_attribs),\n    (\"cat\", OneHotEncoder(), cat_attribs)\n])\n\n# Description before applying transforms\nprint(\"housing_y:\\n\",housing_y.describe())\n\n# Applying log transformation to sales price - remember right-skewed data\nhousing_y_prepared = np.log(housing_y)\n\n# Running transformation pipeline on all other attributes\nhousing_X_prepared = full_pipeline.fit_transform(housing_X)\n\n# Description before applying transform\nprint(\"\\nhousing_y_prepared:\\n\",housing_y_prepared)\n\nhousing_X_prepared","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}